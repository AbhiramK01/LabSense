# ğŸ“ LabSense

<div align="center">

**AI-Powered Coding Lab Exam Evaluation System**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18.3+-61dafb.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.6+-3178c6.svg)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

*Intelligent code evaluation with AI-powered feedback for educational institutions*

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“š Documentation](#-documentation) â€¢ [âœ¨ Features](#-features) â€¢ [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)

</div>

---

## ğŸ“– Overview

**LabSense** is a comprehensive online coding exam platform designed for educational institutions. It provides AI-powered code evaluation, real-time anti-cheat monitoring, and detailed feedback to help students improve their programming skills.

### ğŸ¯ Key Capabilities

- âœ… **Multi-language Support**: Python, JavaScript, Java, C++, Go, and more
- âœ… **AI-Powered Evaluation**: LLM-based code analysis with effort, logic similarity, and test case scoring
- âœ… **Real-time Anti-Cheat**: Fullscreen monitoring, clipboard blocking, tab visibility detection
- âœ… **Comprehensive Feedback**: Detailed AI-generated feedback with strengths, improvements, and scope for growth
- âœ… **Multi-tenant Architecture**: Support for multiple colleges with isolated data
- âœ… **Role-based Access**: Faculty, Student, Admin, and Super Admin roles

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- (Optional) Ollama for local LLM evaluation
- (Optional) Judge0 Cloud API key for multi-language support

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/LabSense2.git
cd LabSense2

# Backend setup
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Frontend setup
cd frontend
npm install
cd ..
```

### Running Locally

```bash
# Terminal 1: Start backend
source .venv/bin/activate
uvicorn app.main:app --reload

# Terminal 2: Start frontend
cd frontend
npm run dev
```

Visit `http://localhost:5173` and log in with:
- **Faculty**: `prof_ada` / `password123`
- **Student**: `alice@student.edu` / `password123`

> ğŸ“˜ **Need more details?** Check out [QUICK_SETUP.md](QUICK_SETUP.md) for step-by-step instructions.

---

## âœ¨ Features

### ğŸ§  Intelligent Code Evaluation

- **Effort Scoring (20%)**: AI evaluates code quality, problem-solving approach, and algorithm choice
- **Logic Similarity (40%)**: Semantic comparison between student code and ideal solutions
- **Test Cases (40%)**: Automated test case execution with public/private test support
- **Full Marks**: Automatic 100% score if all test cases pass

### ğŸ›¡ï¸ Anti-Cheat System

- Fullscreen detection with periodic checks
- Clipboard content blocking (prevents external copy-paste)
- Tab visibility monitoring
- Session tracking and strike system

### ğŸ“Š Comprehensive Feedback

- **Overall Assessment**: General evaluation of the submission
- **Strengths**: What the student did well
- **Areas for Improvement**: Specific issues to address
- **Scope for Improvement**: Detailed suggestions for next steps

### ğŸ« Multi-tenant Support

- College-level isolation
- Department and section management
- Student assignment algorithms
- Exam versioning and history

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Pydantic** - Data validation
- **JWT** - Authentication
- **Ollama/OpenAI/Anthropic** - LLM integration
- **Judge0 Cloud API** - Code execution

### Frontend
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Material-UI (MUI)** - Component library
- **Monaco Editor** - Code editor
- **Vite** - Build tool

### Infrastructure
- **Docker** - Containerization
- **Nginx** - Reverse proxy
- **Cloudflare** - CDN and tunneling

---

## ğŸ“š Documentation

### ğŸ“– Getting Started

| Document | Description |
|----------|-------------|
| [**QUICK_SETUP.md**](QUICK_SETUP.md) | 5-minute setup guide for local LLM |
| [**setup_judge0_cloud.md**](setup_judge0_cloud.md) | Judge0 Cloud API configuration |
| [**LLM_SETUP.md**](LLM_SETUP.md) | Complete LLM integration guide |

### ğŸ§ª Evaluation System

| Document | Description |
|----------|-------------|
| [**EVALUATION_SYSTEM_REDESIGN.md**](EVALUATION_SYSTEM_REDESIGN.md) | Comprehensive evaluation system design |
| [**EVALUATION_IMPLEMENTATION_SUMMARY.md**](EVALUATION_IMPLEMENTATION_SUMMARY.md) | Implementation details and changes |

### ğŸ¤– LLM Integration

| Document | Description |
|----------|-------------|
| [**LOCAL_LLM_SETUP_GUIDE.md**](LOCAL_LLM_SETUP_GUIDE.md) | Detailed local LLM setup (Ollama, llama.cpp, etc.) |
| [**LLM_READY.md**](LLM_READY.md) | Post-setup verification and next steps |
| [**CHECK_LLM_STATUS.md**](CHECK_LLM_STATUS.md) | Troubleshooting LLM connection issues |

### ğŸš€ Deployment

| Document | Description |
|----------|-------------|
| [**deploy/CLOUDFLARE_TUNNEL_SETUP.md**](deploy/CLOUDFLARE_TUNNEL_SETUP.md) | Free deployment with Cloudflare Tunnel (No credit card!) |
| [**deploy/DEPLOYMENT.md**](deploy/DEPLOYMENT.md) | Production deployment guide (VM, Docker, Nginx) |
| [**deploy/env.example**](deploy/env.example) | Environment variables template |

### âš™ï¸ Configuration & Architecture

| Document | Description |
|----------|-------------|
| [**DATA_INTEGRITY_RULES.md**](DATA_INTEGRITY_RULES.md) | Multi-tenant data integrity and conflict prevention |

---

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# Authentication
LABSENSE_SECRET_KEY=your-secret-key-here
LABSENSE_ACCESS_TOKEN_EXPIRE_MINUTES=1440

# LLM Configuration (choose one)
LABSENSE_LLM_URL=http://localhost:11434  # For Ollama
LABSENSE_LLM_MODEL=llama3.1:8b
# OR
OPENAI_API_KEY=your-openai-key
# OR
ANTHROPIC_API_KEY=your-anthropic-key

# Code Execution
LABSENSE_JUDGE0_URL=https://judge0-ce.p.rapidapi.com  # For multi-language support
```

> ğŸ“˜ See [deploy/env.example](deploy/env.example) for all available options.

---

## ğŸ¨ Evaluation System

### Scoring Breakdown

```
Final Score = (Effort Ã— 20%) + (Logic Similarity Ã— 40%) + (Test Cases Ã— 40%) Ã— 100
```

- **Effort (20%)**: Code quality, problem-solving approach, algorithm choice
- **Logic Similarity (40%)**: Semantic comparison with ideal solution
- **Test Cases (40%)**: Public and private test case pass rate

### Special Rules

- âœ… **Full Marks**: 100% if all test cases pass
- âœ… **Multi-language**: Works for Python, JavaScript, Java, C++, Go
- âœ… **AI Feedback**: Detailed, constructive feedback for every submission

> ğŸ“˜ Learn more: [EVALUATION_SYSTEM_REDESIGN.md](EVALUATION_SYSTEM_REDESIGN.md)

---

## ğŸŒ Deployment Options

### Option 1: Cloudflare Tunnel (Free, No Credit Card) â­ Recommended

Perfect for students and quick demos:
- Frontend on Cloudflare Pages (always online)
- Backend via Cloudflare Tunnel from your computer
- Zero cost, no credit card required

> ğŸ“˜ **Guide**: [deploy/CLOUDFLARE_TUNNEL_SETUP.md](deploy/CLOUDFLARE_TUNNEL_SETUP.md)

### Option 2: VM Deployment (Production)

For production use:
- Deploy on Azure/Oracle Cloud/AWS
- Docker Compose setup
- Nginx reverse proxy with HTTPS
- Let's Encrypt certificates

> ğŸ“˜ **Guide**: [deploy/DEPLOYMENT.md](deploy/DEPLOYMENT.md)

---

## ğŸ§ª Testing

### Test Code Execution

```bash
# Test with Python (default, no setup needed)
curl -X POST http://127.0.0.1:8000/evaluate \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "language": "python",
    "student_code": "print(input())",
    "ideal_code": "print(input())",
    "test_cases": [{"input":"5\n","expected_output":"5\n","is_public":true}]
  }'
```

### Verify LLM Connection

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Test LLM
ollama run llama3.1:8b "Say hello"
```

> ğŸ“˜ **Troubleshooting**: [CHECK_LLM_STATUS.md](CHECK_LLM_STATUS.md)

---

## ğŸ“ Project Structure

```
LabSense2/
â”œâ”€â”€ app/                    # Backend FastAPI application
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”œâ”€â”€ core/              # Core utilities (auth, errors)
â”‚   â”œâ”€â”€ evaluator/         # Code evaluation logic
â”‚   â”œâ”€â”€ models/            # Data models
â”‚   â”œâ”€â”€ repositories/      # Data access layer
â”‚   â””â”€â”€ schemas/           # Pydantic schemas
â”œâ”€â”€ frontend/              # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ api.ts         # API client
â”‚   â”‚   â””â”€â”€ App.tsx        # Main app component
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/                  # JSON data storage
â”œâ”€â”€ deploy/                # Deployment configurations
â””â”€â”€ requirements.txt       # Python dependencies
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- [Judge0](https://judge0.com/) - Code execution service
- [Ollama](https://ollama.ai/) - Local LLM inference
- [Monaco Editor](https://microsoft.github.io/monaco-editor/) - Code editor
- [Material-UI](https://mui.com/) - React component library

---

## ğŸ“ Support

- ğŸ“§ **Issues**: [GitHub Issues](https://github.com/yourusername/LabSense2/issues)
- ğŸ“– **Documentation**: See the [Documentation](#-documentation) section above
- ğŸ’¬ **Questions**: Open a discussion on GitHub

---

<div align="center">

**Made with â¤ï¸ for educators and students**

â­ Star this repo if you find it helpful!

</div>
